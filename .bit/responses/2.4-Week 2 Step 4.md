---
files: index.js
stepType: PRmerge
scripts: n/a
week: 2
step: 4
name: Week 2 Step 4
---

## Week 2 Step 4
### Call the Face API P1: Setting [Params](https://idratherbewriting.com/learnapidoc/docapis_doc_parameters.html)

Recall the purpose of this Azure Function:

1. Receive and parse an image from a webpage
2. Call the Face API and analyze the image 

![faceapi](https://user-images.githubusercontent.com/69332964/103604082-1cee0800-4ede-11eb-932e-7bc0f338fa30.png)

*What is happening in this flowchart?*

**Azure Function:** We are now going to be creating parameters that the Azure Function will use to send a request to the Face API Endpoint we just created. 

### Concepts to know:
* GET and POST requests
* API Endpoints
* Async Functions
* Parameters

In this section, we'll be focusing on Part 2.

At this point, your Azure function should look like this:

```js
var multipart = require("parse-multipart");
  
module.exports = async function (context, req) {
    context.log('JavaScript HTTP trigger function processed a request.'); 

    var boundary = multipart.getBoundary(req.headers['content-type']);
    
    var body = req.body;
  
    var parts = multipart.Parse(body, boundary);
};
```


### üìù Task 4: Create a new function and set the parameters of your POST request.
<details>
<summary>‚ùì Where do I begin?</summary>
</br>

Create a new function, outside of  `module.exports`  that will handle analyzing the image (this function is **async** because we will be using the **await** keyword with the API call).

This function will be called `analyzeImage(img)` and takes in one parameter, `img`, that contains the image we're trying to analyze.  Inside, we have two variables involved in the call: `subscriptionKey`  and `uriBase`.  Substitute the necessary values with your own info.

```js
async function analyzeImage(img){
    const subscriptionKey = process.env.SUBSCRIPTIONKEY;
    const uriBase = process.env.ENDPOINT + '/face/v1.0/detect';
}
```

</details>
<br>

<details>
<summary>‚ùì What are the parameters for the request?</summary>
</br>

The documentation for the Face API is here: https://westus.dev.cognitive.microsoft.com/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395236. Read through it, and notice that the request url is this:

`https://{endpoint}/face/v1.0/detect\[?returnFaceId]\[&returnFaceLandmarks]\[&returnFaceAttributes]\[&recognitionModel]\[&returnRecognitionModel][&detectionModel]`

All of the bracketed sections represent possible request parameters. Read through **Request Parameters** section carefully. How can we specify that we want to get the emotion data?

</details>
<br>

<details>
<summary>‚ùìHow do I specify parameters?</summary>
</br>

In order to specify all of our parameters easily, we're going to create a new `URLSearchParams`  object. Here's the object declared for you. I've also already specified one parameter, `returnFaceId`,  as `true` to provide an example. Add in a new parameter that requests emotion.

```js
let params = new URLSearchParams({
	'returnFaceId': 'true',
	'<PARAMETER NAME>': '<PARAMETER VALUE>'     //FILL IN THIS LINE
})
```

</details>
<br>


## üèïÔ∏è To move on, create and merge a pull request with your new additions of code to `index.js`.

#### :exclamation: Remember to use environment variables for your secrets! These can be referenced using `process.env.[your variable name]`